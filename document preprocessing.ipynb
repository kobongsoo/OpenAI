{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d31cdad-529e-42b0-80c6-6f693ce76275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai 버전은 0.27.0 이상, python 3.7.1 이상 에서 만 ChatCompletion.create 함수를 이용할수 있다.\n",
    "\n",
    "#!pip install openai     # openai 설치 \n",
    "#!pip install --upgrade openai # 필요시, openai 업데이트\n",
    "#!pip show openai        # 필요시 openai 버전 확인  \n",
    "#!python -m pip --version #\n",
    "#\n",
    "# openai doc 참고: https://platform.openai.com/docs/api-reference/completions/create?lang=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec149d-06fb-4f08-8d60-b30a09611cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 전처리 예제\n",
    "\n",
    "import os\n",
    "import time\n",
    "from os import sys\n",
    "sys.path.append(\"../BERT/\")\n",
    "from myutils import seed_everything\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import openai\n",
    "#---------------------------------------------------------------------\n",
    "# param\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "# key 지정\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# 모델 - GPT 3.5 Turbo 지정\n",
    "# => 모델 목록은 : https://platform.openai.com/docs/models/gpt-4 참조\n",
    "model = \"gpt-3.5-turbo\"#\"gpt-4-0314\"#\"gpt-4\"#\"gpt-3.5-turbo\"\n",
    "\n",
    "# 2000 청크사이즈로 나눔.=>max가 4096이면 입력=2048, 출력=2048하면 message 구성에 추가적으로 문자가 들어가므로 1900만 해줌.\n",
    "chunk_size=1900\n",
    "\n",
    "DOCUMENTS_FOLDER = '../data11/mpower_doc/out/1/' # 문서들이 있는 폴더 (*반드시 /로 끝나야함)\n",
    "OUT_DOCUMENTS_FOLDER = '../data11/mpower_doc/out-gpt/1/'  # gpt로 text 정리후 저장될 폴더\n",
    "\n",
    "seed=111\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "seed_everything(111)\n",
    "\n",
    "# 정리된 문서 저장될 경로\n",
    "if not os.path.exists(OUT_DOCUMENTS_FOLDER):\n",
    "    os.makedirs(OUT_DOCUMENTS_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb26099-d79b-4272-aa5a-0773a330ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 문서들을 불러와서 DF로 저장\n",
    "\n",
    "from myutils import get_text_chunks, clean_text, getListOfFiles, remove_reverse\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# OUT_FOLDER에 모든 파일 경로를 얻어옴.\n",
    "file_paths = getListOfFiles(DOCUMENTS_FOLDER)\n",
    "assert len(file_paths) > 0 # files가 0이면 assert 발생\n",
    "    \n",
    "print('*file_count: {}, file_list:{}'.format(len(file_paths), file_paths[0:5]))\n",
    "\n",
    "contexts = []\n",
    "titles = []\n",
    "contextids = []\n",
    "\n",
    "# TEXT 추출된 파일들을 읽어오면서 제목(title), 내용(contexts) 등을 저장해 둠.\n",
    "contextid = 1000\n",
    "for idx, file_path in enumerate(tqdm(file_paths)):\n",
    "    if '.ipynb_checkpoints' not in file_path:\n",
    "        sentences = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = f.read()\n",
    "            \n",
    "            #.PAGE:1 패턴을 가지는 문장은 제거함.\n",
    "            pattern = r\"\\.\\.PAGE:\\d+\\s?\"\n",
    "            data = clean_text(text=data, pattern=pattern)\n",
    "            \n",
    "            file_name = os.path.basename(file_path)  # 파일명만 뽑아냄\n",
    "            \n",
    "            #  filename = 5.보안사업부 사업계획.hwp.txt 이면 뒤에 hwp.txt는 제거하고 '5.보안사업부 사업계획' 문자열만 title로 저장함.\n",
    "            file_name = remove_reverse(file_name, '.')# 5.보안사업부 사업계획.hwp 출력됨\n",
    "            file_name = remove_reverse(file_name, '.')# 5.보안사업부 사업계획 출력됨\n",
    "            \n",
    "            contextid += 1\n",
    "            contexts.append(data)     # 파일 내용 저장 \n",
    "            titles.append(file_name)  # 파일명을 제목으로 저장(추후 쿼리할 문장이 됨)\n",
    "            contextids.append(contextid) # contextid 저장 \n",
    "            \n",
    "# 데이터 프레임으로 만듬.\n",
    "df_contexts = pd.DataFrame((zip(contexts, contextids)), columns = ['context','contextid'])\n",
    "df_questions = pd.DataFrame((zip(titles, contextids)), columns = ['question','contextid'])\n",
    "\n",
    "print(f'*len(contexts): {len(contexts)}')\n",
    "print(f'*문서로딩시간: {time.time()-start:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e1d6c-41b8-4787-8d26-38b934b6ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 문서들을 청크로 분할\n",
    "\n",
    "contexts = df_contexts['context'].values.tolist()\n",
    "start = time.time()\n",
    "\n",
    "chunks_list = []\n",
    "for context in tqdm(contexts):\n",
    "    result = get_text_chunks(paragraph = context, chunk_size=chunk_size)\n",
    "    chunks_list.append(result)\n",
    "    \n",
    "print(f'*청크분할시간: {time.time()-start:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749ca2d-1a2c-405d-a1fa-e86e56079d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions['question'][19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9233356-0fd1-42fd-bcbb-4e79204044be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "start = time.time()\n",
    "print(f'len(chunks_list): {len(chunks_list)}')\n",
    "\n",
    "for idx, chunks in enumerate(tqdm(chunks_list)):\n",
    "\n",
    "    if idx < 19:\n",
    "        continue\n",
    "        \n",
    "    result_list = []\n",
    "    for chunk in chunks:\n",
    "        #print(len(chunk))\n",
    "        #print('chunk---------------')\n",
    "        #print(chunk)\n",
    "        #print()\n",
    "        # 메시지 설정\n",
    "        MESSAGES = [\n",
    "                    #{\"role\": \"system\", \"content\": \"You are a helful assistant.\"},\n",
    "                    #{\"role\": \"system\", \"content\": \"입력된 내용을 잘 파악해서 불필요한 코드나 특수문자는 제거하고 내용을 잘 정리해서 보여줘.\"}, \n",
    "                    {\"role\": \"system\", \"content\": \"입력된 내용을 잘 정리해서 처음에 한문장으로 요약해서 설명하고, 이후 특수문자나 기호는 제거하고 문장으로만 자세히 서술해줘.\"}, \n",
    "                    #{\"role\": \"system\", \"content\": \"You are a helful assistant.It understands the entered contents well, removes unnecessary codes or special characters, and displays the contents in a well organized manner.\"}, \n",
    "                    #{\"role\": \"user\", \"content\" : \"How are you?\"},\n",
    "                    #{\"role\": \"assistant\", \"content\" : \"I am doing well\"},\n",
    "                    {\"role\": \"user\", \"content\": chunk}\n",
    "                ]\n",
    "\n",
    "\n",
    "        # ChatGPT-API 호출하기\n",
    "        response = openai.ChatCompletion.create(\n",
    "                    model=model,\n",
    "                    messages=MESSAGES,\n",
    "                    max_tokens=chunk_size, # 토큰 수 => 4096으로 하면 오류 남.\n",
    "                    temperature=0.5,  # temperature 0~2 범위 : 작을수록 정형화된 답변, 클수록 유연한 답변(2는 엉뚱한 답변을 하므로, 1.5정도가 좋은것 같음=기본값은=1)\n",
    "                    top_p=0.1 # 기본값은 1 (0.1이라고 하면 10% 토큰들에서 출력 토큰들을 선택한다는 의미)\n",
    "                )\n",
    "\n",
    "        #print(response)\n",
    "        #print()\n",
    "\n",
    "        result = response['choices'][0]['message']['content']\n",
    "        result_list.append(result)\n",
    "\n",
    "        #print('result---------------')\n",
    "        #print(result)\n",
    "        #print()\n",
    "        \n",
    "    # 문장을 합침\n",
    "    answer = \" \".join(result_list)\n",
    "    \n",
    "    # 파일로 저장.\n",
    "    #file_name = os.path.basename(file_paths[idx])  # 파일명만 뽑아냄\n",
    "    \n",
    "    file_name = df_questions['question'][idx] + \".txt\"\n",
    "    \n",
    "    tgtPath = OUT_DOCUMENTS_FOLDER + file_name\n",
    "    print(tgtPath)\n",
    "    with open(tgtPath, 'w', encoding='utf-8') as f:\n",
    "        f.write(answer+'\\n')\n",
    "\n",
    "print(f'*gpt로 문서 정리 총 시간: {time.time()-start:.4f}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388970a-62eb-430f-a82b-c7bb6403a51b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
